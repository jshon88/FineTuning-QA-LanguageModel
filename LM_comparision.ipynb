{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import math\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "# from tqdm.notebook import tqdm\n",
    "from datasets import load_dataset\n",
    "# from huggingface_hub import list_datasets\n",
    "# from datasets import load_metric\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "from transformers import DistilBertTokenizerFast, AutoTokenizer, BertForQuestionAnswering\n",
    "from transformers import DistilBertForQuestionAnswering, AutoModelForQuestionAnswering\n",
    "from transformers import get_scheduler\n",
    "from transformers import pipeline\n",
    "from transformers import DefaultDataCollator\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "import collections\n",
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_squad(path):\n",
    "    path = Path(path)\n",
    "    with open(path, 'rb') as f:\n",
    "        squad_dict = json.load(f)\n",
    "\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    for group in squad_dict['data']:\n",
    "        for passage in group['paragraphs']:\n",
    "            context = passage['context']\n",
    "            for qa in passage['qas']:\n",
    "                question = qa['question']\n",
    "                for answer in qa['answers']:\n",
    "                    contexts.append(context)\n",
    "                    questions.append(question)\n",
    "                    answers.append(answer)\n",
    "\n",
    "    return contexts, questions, answers\n",
    "\n",
    "def add_end_idx(answers, contexts):\n",
    "    for answer, context in zip(answers, contexts):\n",
    "        gold_text = answer['text']\n",
    "        start_idx = answer['answer_start']\n",
    "        end_idx = start_idx + len(gold_text)\n",
    "\n",
    "        # sometimes squad answers are off by a character or two â€“ fix this\n",
    "        if context[start_idx:end_idx] == gold_text:\n",
    "            answer['answer_end'] = end_idx\n",
    "        elif context[start_idx-1:end_idx-1] == gold_text:\n",
    "            answer['answer_start'] = start_idx - 1\n",
    "            answer['answer_end'] = end_idx - 1     # When the gold label is off by one character\n",
    "        elif context[start_idx-2:end_idx-2] == gold_text:\n",
    "            answer['answer_start'] = start_idx - 2\n",
    "            answer['answer_end'] = end_idx - 2     # When the gold label is off by two characters\n",
    "\n",
    "def add_token_positions(encodings, answers):\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for i in range(len(answers)):\n",
    "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
    "        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'] - 1))\n",
    "        # if None, the answer passage has been truncated\n",
    "        if start_positions[-1] is None:\n",
    "            start_positions[-1] = tokenizer.model_max_length\n",
    "        if end_positions[-1] is None:\n",
    "            end_positions[-1] = tokenizer.model_max_length\n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "\n",
    "class SquadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "def QAinference(model, tokenizer, question, context, device, usepipeline=True):\n",
    "    if usepipeline ==True:\n",
    "        if device.type == 'cuda':\n",
    "            question_answerer = pipeline(\"question-answering\", model=model, tokenizer=tokenizer, device=0) #device=0 means cuda\n",
    "        else:\n",
    "            question_answerer = pipeline(\"question-answering\", model=model, tokenizer=tokenizer) \n",
    "        answers=question_answerer(question=question, context=context)\n",
    "        print(answers) #'answer', 'score', 'start', 'end'\n",
    "    else:\n",
    "        inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        #Get the highest probability from the model output for the start and end positions:\n",
    "        answer_start_index = outputs.start_logits.argmax()\n",
    "        answer_end_index = outputs.end_logits.argmax()\n",
    "        #predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "        #Decode the predicted tokens to get the answer:\n",
    "        predict_answer_tokens = inputs['input_ids'][0, answer_start_index : answer_end_index + 1]\n",
    "        answers=tokenizer.decode(predict_answer_tokens)\n",
    "        print(answers)\n",
    "    return answers\n",
    "\n",
    "max_length = 384\n",
    "stride = 128\n",
    "def preprocess_training_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\") #new add\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx = sample_map[i] #new add\n",
    "        #answer = answers[i]\n",
    "        answer = answers[sample_idx] # sample_idx from sample_map\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label it (0, 0)\n",
    "        # if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs\n",
    "\n",
    "def preprocess_validation_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]] #100 questions\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")#100, if no overflow, then sample_map=0-99\n",
    "    example_ids = []\n",
    "\n",
    "    for i in range(len(inputs[\"input_ids\"])):\n",
    "        sample_idx = sample_map[i]\n",
    "        example_ids.append(examples[\"id\"][sample_idx]) #get example id strings\n",
    "\n",
    "        sequence_ids = inputs.sequence_ids(i) #[None, 0... None, 1... 1]\n",
    "        offset = inputs[\"offset_mapping\"][i] #100 size array of tuple (0, 4)\n",
    "        inputs[\"offset_mapping\"][i] = [\n",
    "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "        ] #put None in sequence_id==1, i.e., put questions to None\n",
    "\n",
    "    inputs[\"example_id\"] = example_ids #string list\n",
    "    return inputs\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=384,\n",
    "        truncation=\"only_second\",\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        answer = answers[i]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label it (0, 0)\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs\n",
    "\n",
    "def testdataset(raw_datasets):\n",
    "    oneexample = raw_datasets[\"train\"][0]\n",
    "    #'id', 'title','context', 'question', 'answers' (text, answer_start),  \n",
    "    print(\"Context: \", oneexample[\"context\"])\n",
    "    print(\"Question: \", oneexample[\"question\"])\n",
    "    print(\"Answer: \", oneexample[\"answers\"])#dict with 'text' (list of strings) and 'answer_start' list of integer [515]\n",
    "    #During training, there is only one possible answer. We can double-check this by using the Dataset.filter() method:\n",
    "    print(raw_datasets[\"train\"].filter(lambda x: len(x[\"answers\"][\"text\"]) != 1))\n",
    "    #For evaluation, however, there are several possible answers for each sample, which may be the same or different:\n",
    "    valkey=\"validation\" #'test' #\"validation\"\n",
    "    print(raw_datasets[valkey][0][\"answers\"])\n",
    "    print(raw_datasets[valkey][2][\"answers\"])\n",
    "\n",
    "    #We can pass to our tokenizer the question and the context together, and it will properly insert the special tokens [CLS], [SEP]\n",
    "    inputs = tokenizer(oneexample[\"question\"], oneexample[\"context\"])\n",
    "    print(tokenizer.decode(inputs[\"input_ids\"])) #[CLS] question [SEP] xxxx [SEP]\n",
    "    #The labels will then be the index of the tokens starting and ending the answer\n",
    "\n",
    "    #deal with very long contexts, use sliding window\n",
    "    inputs = tokenizer(\n",
    "        oneexample[\"question\"],\n",
    "        oneexample[\"context\"],\n",
    "        max_length=100,\n",
    "        truncation=\"only_second\", #truncate the context (in the second position)\n",
    "        stride=50, #use a sliding window of 50 tokens\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "    )\n",
    "    print(inputs.keys()) #['input_ids', 'attention_mask', 'offset_mapping', 'overflow_to_sample_mapping']\n",
    "    for ids in inputs[\"input_ids\"]: #4 features with overlaps\n",
    "        print(tokenizer.decode(ids))\n",
    "        #split into four inputs, each of them containing the question and some part of the context.\n",
    "        #some training examples where the answer is not included in the context: labels will be start_position = end_position = 0 (so we predict the [CLS] token)\n",
    "    \n",
    "\n",
    "    multiexamples = raw_datasets[\"train\"][2:6]\n",
    "    inputs = tokenizer(\n",
    "        multiexamples[\"question\"],\n",
    "        multiexamples[\"context\"],\n",
    "        max_length=100,\n",
    "        truncation=\"only_second\",\n",
    "        stride=50,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "    )\n",
    "    print(f\"The 4 examples gave {len(inputs['input_ids'])} features.\") #17 features\n",
    "    print(f\"Here is where each comes from: {inputs['overflow_to_sample_mapping']}.\") #[0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]\n",
    "    #'overflow_to_sample_mapping': one example might give us several features if it has a long context, e.g. 0 example has been split into 5 parts\n",
    "    #'offset_mapping': [[(0,0),(0,3),(3,4)...] ] The offset mappings will give us a map from token to character position in the original context. help us compute the start_positions and end_positions.\n",
    "\n",
    "    answers = multiexamples[\"answers\"] #length of 4 \n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    print(inputs[\"offset_mapping\"]) #size 17\n",
    "    for i, offset in enumerate(inputs[\"offset_mapping\"]): #17 array, each array (offset) has 100 elements tuples of two integers representing the span of characters inside the original context.\n",
    "        sample_idx = inputs[\"overflow_to_sample_mapping\"][i] #0 current feature map to which sample\n",
    "        answer = answers[sample_idx] #get the groundtruth answer in sample idx\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i) #[None 0 0... None 1 1 1... None], 100 tokens belongs to 0 or 1 or None\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx #sequence 1 starts at 17th token\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1 #98\n",
    "\n",
    "        # If the answer is not fully inside the context, label is (0, 0); offset[context_start] in the first part is (0,13), second part is (156, 160), (438, 440)\n",
    "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char: #answer not in this region\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start #17\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1) #find the answer start token index\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1) #find the answer end token index\n",
    "\n",
    "    print(start_positions) #17 elements, if position is 0, means no answer in this region\n",
    "    print(end_positions)\n",
    "\n",
    "    idx = 0 #use idx=0 as example\n",
    "    sample_idx = inputs[\"overflow_to_sample_mapping\"][idx] #0-th sample\n",
    "    answer = answers[sample_idx][\"text\"][0] #ground truth answer text\n",
    "    start = start_positions[idx]\n",
    "    end = end_positions[idx]\n",
    "    labeled_answer = tokenizer.decode(inputs[\"input_ids\"][idx][start : end + 1])\n",
    "    print(f\"Theoretical answer: {answer}, labels give: {labeled_answer}\")\n",
    "\n",
    "    idx = 4 #use idx=4 as example\n",
    "    sample_idx = inputs[\"overflow_to_sample_mapping\"][idx] #sample_idx is 1\n",
    "    answer = answers[sample_idx][\"text\"][0]\n",
    "    start = start_positions[idx]\n",
    "    end = end_positions[idx]\n",
    "    labeled_answer = tokenizer.decode(inputs[\"input_ids\"][idx][start : end + 1])\n",
    "    print(f\"Theoretical answer: {answer}, labels give: {labeled_answer}\")\n",
    "    #means the answer is not in the context chunk of that feature\n",
    "\n",
    "def compute_metrics(start_logits, end_logits, features, examples):\n",
    "    n_best = 20\n",
    "    max_answer_length = 30\n",
    "\n",
    "    #features is after tokenization, examples are original dataset\n",
    "    example_to_features = collections.defaultdict(list)\n",
    "    for idx, feature in enumerate(features):\n",
    "        example_to_features[feature[\"example_id\"]].append(idx)\n",
    "\n",
    "    predicted_answers = []\n",
    "    for example in tqdm(examples):\n",
    "        example_id = example[\"id\"]\n",
    "        context = example[\"context\"]\n",
    "        answers = []\n",
    "\n",
    "        # Loop through all features associated with that example\n",
    "        for feature_index in example_to_features[example_id]:\n",
    "            start_logit = start_logits[feature_index]\n",
    "            end_logit = end_logits[feature_index]\n",
    "            offsets = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # Skip answers that are not fully in the context\n",
    "                    if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                        continue\n",
    "                    # Skip answers with a length that is either < 0 or > max_answer_length\n",
    "                    if (\n",
    "                        end_index < start_index\n",
    "                        or end_index - start_index + 1 > max_answer_length\n",
    "                    ):\n",
    "                        continue\n",
    "\n",
    "                    answer = {\n",
    "                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n",
    "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
    "                    }\n",
    "                    answers.append(answer)\n",
    "\n",
    "        # Select the answer with the best score\n",
    "        if len(answers) > 0:\n",
    "            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "            predicted_answers.append(\n",
    "                {\"id\": example_id, \"prediction_text\": best_answer[\"text\"]}\n",
    "            )\n",
    "        else:\n",
    "            predicted_answers.append({\"id\": example_id, \"prediction_text\": \"\"})\n",
    "\n",
    "    theoretical_answers = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in examples]\n",
    "    return metric.compute(predictions=predicted_answers, references=theoretical_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '5733be284776f41900661182', 'title': 'University_of_Notre_Dame', 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.', 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}\n"
     ]
    }
   ],
   "source": [
    "# Load a dataset and print the first example in the training set\n",
    "squad_dataset = load_dataset('squad')\n",
    "print(squad_dataset['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/bert-base-cased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Model 1: \"deepset/bert-base-cased-squad2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepset/bert-base-cased-squad2\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"deepset/bert-base-cased-squad2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForQuestionAnswering(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87599/87599 [00:34<00:00, 2572.54 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1562.25 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10570\n",
      "100\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'example_id'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "valkeyname=\"validation\" #\"test\"\n",
    "tokenized_datasets = {}\n",
    "tokenized_datasets[\"train\"] = squad_dataset[\"train\"].map(preprocess_training_examples, batched=True, remove_columns=squad_dataset[\"train\"].column_names)\n",
    "#['input_ids', 'attention_mask', 'start_positions', 'end_positions']\n",
    "small_eval_set = squad_dataset[valkeyname].select(range(100))\n",
    "validation_dataset = small_eval_set.map(\n",
    "    preprocess_validation_examples, #preprocess_function, #preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=squad_dataset[valkeyname].column_names,\n",
    ")\n",
    "print(len(squad_dataset[valkeyname])) #1000\n",
    "print(len(validation_dataset)) #1011\n",
    "eval_set_for_model = validation_dataset.remove_columns([\"example_id\", \"offset_mapping\"])\n",
    "print(validation_dataset.features.keys())#['input_ids', 'attention_mask', 'offset_mapping', 'example_id']\n",
    "print(eval_set_for_model.features.keys())#['input_ids', 'attention_mask']\n",
    "eval_set_for_model.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DefaultDataCollator()\n",
    "train_dataloader = DataLoader(tokenized_datasets[\"train\"], batch_size=8, shuffle=True, collate_fn=data_collator)\n",
    "eval_dataloader = DataLoader(\n",
    "    eval_set_for_model, batch_size=8, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.53k/4.53k [00:00<00:00, 7.93MB/s]\n",
      "Downloading extra modules: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.32k/3.32k [00:00<00:00, 8.70MB/s]\n"
     ]
    }
   ],
   "source": [
    "metric = evaluate.load(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87599/87599 [00:34<00:00, 2572.54 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1562.25 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10570\n",
      "100\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'example_id'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 1\n",
    "\n",
    "valkeyname=\"validation\" #\"test\"\n",
    "tokenized_datasets = {}\n",
    "tokenized_datasets[\"train\"] = squad_dataset[\"train\"].map(preprocess_training_examples, batched=True, remove_columns=squad_dataset[\"train\"].column_names)\n",
    "#['input_ids', 'attention_mask', 'start_positions', 'end_positions']\n",
    "small_eval_set = squad_dataset[valkeyname].select(range(100))\n",
    "validation_dataset = small_eval_set.map(\n",
    "    preprocess_validation_examples, #preprocess_function, #preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=squad_dataset[valkeyname].column_names,\n",
    ")\n",
    "print(len(squad_dataset[valkeyname])) #1000\n",
    "print(len(validation_dataset)) #1011\n",
    "eval_set_for_model = validation_dataset.remove_columns([\"example_id\", \"offset_mapping\"])\n",
    "print(validation_dataset.features.keys())#['input_ids', 'attention_mask', 'offset_mapping', 'example_id']\n",
    "print(eval_set_for_model.features.keys())#['input_ids', 'attention_mask']\n",
    "eval_set_for_model.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DefaultDataCollator()\n",
    "train_dataloader = DataLoader(tokenized_datasets[\"train\"], batch_size=8, shuffle=True, collate_fn=data_collator)\n",
    "eval_dataloader = DataLoader(\n",
    "    eval_set_for_model, batch_size=8, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [02:45<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10570/10570 [00:01<00:00, 9470.85it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exact_match': 0.6149479659413434, 'f1': 0.6551353040585767}\n"
     ]
    }
   ],
   "source": [
    "# Model 1 evaluation\n",
    "model.eval()\n",
    "\n",
    "num_val_steps = len(eval_dataloader)\n",
    "valprogress_bar = tqdm(range(num_val_steps))\n",
    "start_logits = []\n",
    "end_logits = []\n",
    "for batch in eval_dataloader:\n",
    "    #batch = {k: batch[k].to(device) for k in batch.column_names}\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    start_logits.append(outputs.start_logits.cpu().numpy())\n",
    "    end_logits.append(outputs.end_logits.cpu().numpy())\n",
    "start_logits = np.concatenate(start_logits) #8, 384 array to (102,384)\n",
    "end_logits = np.concatenate(end_logits)\n",
    "dataset_len=len(validation_dataset) #103\n",
    "start_logits = start_logits[: dataset_len]\n",
    "end_logits = end_logits[: dataset_len]\n",
    "metrics1 = compute_metrics(\n",
    "    start_logits, end_logits, validation_dataset, squad_dataset[valkeyname]\n",
    ")\n",
    "print(metrics1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Model 2: \"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForQuestionAnswering(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10570\n",
      "100\n",
      "dict_keys(['input_ids', 'attention_mask', 'offset_mapping', 'example_id'])\n",
      "dict_keys(['input_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "# Model 2\n",
    "\n",
    "valkeyname=\"validation\" #\"test\"\n",
    "tokenized_datasets = {}\n",
    "tokenized_datasets[\"train\"] = squad_dataset[\"train\"].map(preprocess_training_examples, batched=True, remove_columns=squad_dataset[\"train\"].column_names)\n",
    "#['input_ids', 'attention_mask', 'start_positions', 'end_positions']\n",
    "small_eval_set = squad_dataset[valkeyname].select(range(100))\n",
    "validation_dataset = small_eval_set.map(\n",
    "    preprocess_validation_examples, #preprocess_function, #preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=squad_dataset[valkeyname].column_names,\n",
    ")\n",
    "print(len(squad_dataset[valkeyname])) #1000\n",
    "print(len(validation_dataset)) #1011\n",
    "eval_set_for_model = validation_dataset.remove_columns([\"example_id\", \"offset_mapping\"])\n",
    "print(validation_dataset.features.keys())#['input_ids', 'attention_mask', 'offset_mapping', 'example_id']\n",
    "print(eval_set_for_model.features.keys())#['input_ids', 'attention_mask']\n",
    "eval_set_for_model.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DefaultDataCollator()\n",
    "train_dataloader = DataLoader(tokenized_datasets[\"train\"], batch_size=8, shuffle=True, collate_fn=data_collator)\n",
    "eval_dataloader = DataLoader(\n",
    "    eval_set_for_model, batch_size=8, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/13 [2:57:44<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10570/10570 [00:01<00:00, 9311.19it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exact_match': 0.02838221381267739, 'f1': 0.05430206448974767}\n"
     ]
    }
   ],
   "source": [
    "# Model 2 evaluation\n",
    "model.eval()\n",
    "\n",
    "num_val_steps = len(eval_dataloader)\n",
    "valprogress_bar = tqdm(range(num_val_steps))\n",
    "start_logits = []\n",
    "end_logits = []\n",
    "for batch in eval_dataloader:\n",
    "    #batch = {k: batch[k].to(device) for k in batch.column_names}\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    start_logits.append(outputs.start_logits.cpu().numpy())\n",
    "    end_logits.append(outputs.end_logits.cpu().numpy())\n",
    "start_logits = np.concatenate(start_logits) #8, 384 array to (102,384)\n",
    "end_logits = np.concatenate(end_logits)\n",
    "dataset_len=len(validation_dataset) #103\n",
    "start_logits = start_logits[: dataset_len]\n",
    "end_logits = end_logits[: dataset_len]\n",
    "metrics2 = compute_metrics(\n",
    "    start_logits, end_logits, validation_dataset, squad_dataset[valkeyname]\n",
    ")\n",
    "print(metrics2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exact_match</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bert-base-cased-squad2</th>\n",
       "      <td>0.614948</td>\n",
       "      <td>0.655135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbert-base-uncased</th>\n",
       "      <td>0.028382</td>\n",
       "      <td>0.067235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         exact_match  F1 Score\n",
       "Model                                         \n",
       "bert-base-cased-squad2      0.614948  0.655135\n",
       "distilbert-base-uncased     0.028382  0.067235"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = ['bert-base-cased-squad2', 'distilbert-base-uncased']\n",
    "eval_result = {\n",
    "    'Model': models,\n",
    "    'exact_match': [metrics1['exact_match'], metrics2['exact_match']],\n",
    "    'F1 Score': [metrics1['f1'], metrics2['f1']]\n",
    "}\n",
    "df_model_evaluation = pd.DataFrame(eval_result).set_index('Model')\n",
    "df_model_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Reset index to have 'Model' as a column\n",
    "df_plot = df_model_evaluation.reset_index()\n",
    "\n",
    "# Melt the DataFrame for easier plotting\n",
    "df_melted = df_plot.melt(id_vars='Model', var_name='Metric', value_name='Score')\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='Metric', y='Score', hue='Model', data=df_melted)\n",
    "plt.title('Model Evaluation Metrics Comparison')\n",
    "plt.ylabel('Score')\n",
    "plt.savefig('QAModels_Evaluation.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train distilbert-base-uncased model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "num_epochs = 2\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        #batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "        #outputs = model(**batch)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "        #sequence classification: outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss = outputs[0] #same loss results\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    start_logits = []\n",
    "    end_logits = []\n",
    "    num_val_steps = len(eval_dataloader)\n",
    "    for batch in eval_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        start_logits.append(outputs.start_logits.cpu().numpy())\n",
    "        end_logits.append(outputs.end_logits.cpu().numpy())\n",
    "    start_logits = np.concatenate(start_logits) #8, 384 array to (102,384)\n",
    "    end_logits = np.concatenate(end_logits)\n",
    "    dataset_len=len(validation_dataset) #103\n",
    "    start_logits = start_logits[: dataset_len]\n",
    "    end_logits = end_logits[: dataset_len]\n",
    "    metrics = compute_metrics(\n",
    "        start_logits, end_logits, validation_dataset, squad_dataset[valkeyname]\n",
    "    )\n",
    "    print(f\"epoch {epoch}:\", metrics)\n",
    "\n",
    "outputpath='./output/distilbert-base-uncased/'\n",
    "tokenizer.save_pretrained(outputpath)\n",
    "torch.save(model.state_dict(), os.path.join(outputpath, 'savedmodel.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2 evaluation after training\n",
    "model.eval()\n",
    "\n",
    "num_val_steps = len(eval_dataloader)\n",
    "valprogress_bar = tqdm(range(num_val_steps))\n",
    "start_logits = []\n",
    "end_logits = []\n",
    "for batch in eval_dataloader:\n",
    "    #batch = {k: batch[k].to(device) for k in batch.column_names}\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    start_logits.append(outputs.start_logits.cpu().numpy())\n",
    "    end_logits.append(outputs.end_logits.cpu().numpy())\n",
    "start_logits = np.concatenate(start_logits) #8, 384 array to (102,384)\n",
    "end_logits = np.concatenate(end_logits)\n",
    "dataset_len=len(validation_dataset) #103\n",
    "start_logits = start_logits[: dataset_len]\n",
    "end_logits = end_logits[: dataset_len]\n",
    "metrics3 = compute_metrics(\n",
    "    start_logits, end_logits, validation_dataset, squad_dataset[valkeyname]\n",
    ")\n",
    "print(metrics3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['bert-base-cased-squad2', 'distilbert-base-uncased', 'distilbert-base-uncased_fine_tuning']\n",
    "eval_result = {\n",
    "    'Model': models,\n",
    "    'exact_match': [metrics1['exact_match'], metrics2['exact_match'], metrics3['exact_match']],\n",
    "    'F1 Score': [metrics1['f1'], metrics2['f1'], metrics3['f1']]\n",
    "}\n",
    "df_model_evaluation = pd.DataFrame(eval_result).set_index('Model')\n",
    "df_model_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Reset index to have 'Model' as a column\n",
    "df_plot = df_model_evaluation.reset_index()\n",
    "\n",
    "# Melt the DataFrame for easier plotting\n",
    "df_melted = df_plot.melt(id_vars='Model', var_name='Metric', value_name='Score')\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='Metric', y='Score', hue='Model', data=df_melted)\n",
    "plt.title('Model Evaluation Metrics Comparison')\n",
    "plt.ylabel('Score')\n",
    "plt.savefig('QAModels_Evaluation_fine_tuning.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
